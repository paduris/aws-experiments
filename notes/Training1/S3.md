**Amazon S3**
    * Amazon S3 is one of the main building blocks of AWS
    * It's advertised as "infinitely scaling" storage
    * It's widely popular and deserves its own section
    * Many websites use AWS S3 as a backbone
    * Many AWS services uses AWS S3 as an integration as well

* Amazon S3 allows people to store **objects** (files) in **buckets** (directories)
* **Buckets** must have a **globally unique name** across the all the AWS accounts
* **Buckets** are defined at **regional level**
* Naming convention 
    * No Uppercase
    * No Underscore
    * 3-63 characters long
    * Not an IP
    * Must start with a lowercase letter or number
    
* Objects have Key -> The key is **full path**:
    * Example: _<my-bucket>/<my_folder>/suresh/test.jpg_
* There is no concept of directories 
* Object values are the content of the body 
    * Max size - **5TB**
    * If you're uploading more than 5GB, use **multi-part** upload
    * You will get Http 200 for a successful upload to S3 bucket
* **Metadata** - list of text key/value pairs - system or user metadata
* **Tags** - Unicode key/value pair - upto 10 - useful for security / lifecycle
* **Version ID** - if we have enabled versioning 
    * Best practice to version your buckets - protect against unintended deletes
    * Any file that is not versioned prior to enabling versioning will have version **"null"**
* [Immediate Consistency] If you write a new file and read it immediately afterwards, you will be able to view that data
* [Eventual Consistency]  If you update or delete an existing file and read it immediately, you may get the older version or you may not, 
  basically changes to objects can take a little bit of time to propagate 
  
**S3 Storage Classes**
    * S3 Standard : 99.99% availability , 99.99999999999% durability
    * S3 - IA ( Infrequently Accessed ) : For data that is accessed less frequently but requires rapid access when needed. Lower fee than S3 but you are charged a retrieval fee.  
    * S3 One Zone - IA : only one zone. 
    * S3 - Intelligent Tier : Designed for optimized costs by automatically moving data to the most cost- effective access tier without performance impact or operational overhead.
    * S3 - Glacier : secure, durable and low cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive within or cheaper than on premises solutions. Retrieval times configurable from minutes to hours
    * S3 Glacier Deep Archive: Amazon's S3's lowest cost storage class where a retrieval time of 12 hours is acceptable.
    
**S3 Charges**  
    * Storage
    * Requests
    * Storage Management Pricing
    * Data transfer pricing
    * Transfer Acceleration
        * Enables fast,easy and secure transfer of files over long distances between your users and S3 buckets, 
          Transfer Acceleration takes advantage of Amazon's Cloud Front globally distributed edge locations. 
          As the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path
    * Cross Region Replication Pricing
  
  
* **Encryption**
    * **SSE-S3** : encrypts S3 objects using keys handled & managed by AWS
        * Object is encrypted server side 
        * AES-256 encryption type 
        * Must set header: **"x-amz-server-side-encryption":"AES256"**
    * **SSE-KMS** : leverage AWS key management service to manage encryption keys 
        * KMS Advantages : user control + audit trail
        * Object is encrypted server side
        * Must ser header: **"x-amz-server-side-encryption":"aws:kms"**
    * **SSE-C**: server side encryption using data keys fully managed by the customer outside of AWS
        * **HTTPS** must be used
        * Amazon S3 does not store the encryption key you provide, just throws it away after use
        * Encryption key must provided in HTTP headers, for every HTTP requests made
    * **Client Side Encryption**
        * Client library such as the Amazon S3 Encryption Client
        * Clients must encrypt data themselves when retrieving from S3
        * Clients must decrypt data themselves when retrieving from S3
        * Customer fully manages the keys and encryption cycle
    * **Encryption in transit (SSL)**
        * AWS S3 exposes 
            * Http endpoint : non encrypted
            * Https endpoint: encryption in flight
            * You're free to use the endpoint you want, but HTTPS is recommended
            * HTTPS is mandatory for SSE-C
      
* **S3 MFA Delete**
    * MFA (multi factor authentication) forces user to generate a code on a device usually a mobile phone before doing an important operation on S3
    * To use MFA-Delete, enable versioning on the S3 bucket
    * You will need MFA to 
        * permanently delete an object version
        * suspend versioning on the bucket
    * You won't need MFA for 
        * enabling versioning
        * listing deleted versions
    * Only one bucket owner (root account) can enable/disable MFA-Delete
    * MFA-Delete currently can only be enabled using the AWS CLI
           
            # generate root access keys
            aws configure --profile root-spaduri
            # enable mfa delete
            aws s3api put-bucket-versioning --bucket mfa-resource --versioning-configuration Status=Enabled,MFADelete=Enabled --mfa "arn:aws:iam::833815794274:mfa/root-account-mfa-device 764790" --profile root-spaduri
            # disable mfa delete
            aws s3api put-bucket-versioning --bucket mfa-resource --versioning-configuration Status=Enabled,MFADelete=Disabled --mfa "arn:aws:iam::833815794274:mfa/root-account-mfa-device 764790" --profile root-spaduri
            # delete the root credentials in the IAM console!!!
        
**S3 Default Encryption vs Bucket Policies**
       * The old way to enable default encryption was to use a bucket policy and refuse any HTTP command without the proper headers:
       * New way is enable default encryption check on the bucket
       
**S3 Access Logs**
    
 **S3 Cross Region**
        * Must enable versioning both source and destination buckets
        * Buckets must be in different AWS regions
        * Can be in different accounts
        * Copying is asynchronous replicated
        * Files in the existing bucket are not replicated automatically
        * All subsequent files will be replicated automatically
        * Delete markers are not 
        * Must give proper IAM permissions to S3
        * Use cases: compliance, lower latency access, replication across accounts
    
 **S3 Presigned URLS**  - Comment - I need to test this 
        * Can generate pre-signed URLs using SDK or CLI
            * For downloads ( easy, can use the CLI)
            * For uploads (harder, must use the SDK)
        * Valid for default of 3600 seconds, can change timeout with - expires-in[TIME_BY_SECONDS] argument
        * Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET/PUT
        * Examples:
            * Allow only logged-in users to download a premium video on your S3 bucket
            * Allow an ever changing list of users to download files by generating URLs dynamically
            * Allow temporarily a user to upload a file to a precise location in our bucket
            
 
  **Snowball**
    
    
    
    
    
    
    
    
    
    
    
       